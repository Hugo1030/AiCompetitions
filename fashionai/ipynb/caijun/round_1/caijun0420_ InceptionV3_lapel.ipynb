{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据\n",
    "-  label 文件一共有 79572 行\n",
    "- 各种维度混合在一起\n",
    "- 我们的目的是切分开各种维度, 进行训练和模拟\n",
    "- 那么首先取出个标签的图片进行聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/collar_design_labels/4d8a38b29930a403e5...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nnynn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/collar_design_labels/bd0981f231180d2b00...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/collar_design_labels/26937e1724feadfe39...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>ynnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/collar_design_labels/cf4140ec542887270f...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/collar_design_labels/50644b2b9de045f2d1...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class  \\\n",
       "0  Images/collar_design_labels/4d8a38b29930a403e5...  collar_design_labels   \n",
       "1  Images/collar_design_labels/bd0981f231180d2b00...  collar_design_labels   \n",
       "2  Images/collar_design_labels/26937e1724feadfe39...  collar_design_labels   \n",
       "3  Images/collar_design_labels/cf4140ec542887270f...  collar_design_labels   \n",
       "4  Images/collar_design_labels/50644b2b9de045f2d1...  collar_design_labels   \n",
       "\n",
       "   label  \n",
       "0  nnynn  \n",
       "1  nynnn  \n",
       "2  ynnnn  \n",
       "3  nynnn  \n",
       "4  nynnn  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./Annotations/label.csv', header=None)\n",
    "df_train.columns = ['image_id', 'class', 'label']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['collar_design_labels', 'neckline_design_labels', 'skirt_length_labels',\n",
    "          'sleeve_length_labels', 'neck_design_labels', 'coat_length_labels', 'lapel_design_labels',\n",
    "          'pant_length_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lapel_design_labels: 7034\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/lapel_design_labels/6cd79483ca0040a67fe...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "      <td>nnnny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/lapel_design_labels/b169d0a8a9dd0301ff3...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/lapel_design_labels/2dd8c8d311247ca384a...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/lapel_design_labels/2da3f9e7243ab23014a...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "      <td>nnnny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/lapel_design_labels/47094db231099dc959c...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "      <td>nnynn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                class  \\\n",
       "0  Images/lapel_design_labels/6cd79483ca0040a67fe...  lapel_design_labels   \n",
       "1  Images/lapel_design_labels/b169d0a8a9dd0301ff3...  lapel_design_labels   \n",
       "2  Images/lapel_design_labels/2dd8c8d311247ca384a...  lapel_design_labels   \n",
       "3  Images/lapel_design_labels/2da3f9e7243ab23014a...  lapel_design_labels   \n",
       "4  Images/lapel_design_labels/47094db231099dc959c...  lapel_design_labels   \n",
       "\n",
       "   label  \n",
       "0  nnnny  \n",
       "1  nynnn  \n",
       "2  nynnn  \n",
       "3  nnnny  \n",
       "4  nnynn  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_class = classes[6]\n",
    "df_load = df_train[(df_train['class'] == cur_class)].copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "\n",
    "print('{0}: {1}'.format(cur_class, len(df_load)))\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(df_load)\n",
    "n_class = len(df_load['label'][0])\n",
    "width = 299 # 定义图片大小\n",
    "\n",
    "X = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "y = np.zeros((n, n_class), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Images/lapel_design_labels/6cd79483ca0040a67fe70f3f67882955.jpg\n"
     ]
    }
   ],
   "source": [
    "print('./{0}'.format(df_load['image_id'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7034/7034 [00:49<00:00, 141.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n)):\n",
    "    tmp_label = df_load['label'][i]\n",
    "    if len(tmp_label) > n_class:\n",
    "        print(df_load['image_id'][i])\n",
    "    X[i] = cv2.resize(cv2.imread('./{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "    y[i][tmp_label.find('y')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7034, 299, 299, 3), (7034, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(12, 7))\n",
    "#for i in range(8):\n",
    "#    random_index = random.randint(0, n-1)\n",
    "#    plt.subplot(2, 4, i+1)\n",
    "#    plt.imshow(X[random_index][:,:,::-1])\n",
    "#    plt.title(y[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.regularizers import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.regularizers import *\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = InceptionV3(include_top=False, input_shape=(width, width, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((width, width, 3))\n",
    "\n",
    "x = inputs\n",
    "x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "x = cnn_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lapel'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "prefix_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练/测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6189, 299, 299, 3), (6189, 5))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.12, random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "adam = Adam(lr=0.001) \n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Set a learning rate annealer\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "#                                             patience=3,\n",
    "#                                             verbose=1,\n",
    "#                                             factor=0.1,\n",
    "#                                             min_lr=0.00001)\n",
    "epochs = 16\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center = False, # set input mean to 0 over the dataset\n",
    "        samplewise_center = False, # set each sample mean to 0\n",
    "        featurewise_std_normalization = False, # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization = False, # divide each input by its std\n",
    "        zca_whitening = False, # apply ZCA whitening\n",
    "        rotation_range = 10, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.05, # randomly zoom image\n",
    "        width_shift_range = 0.075, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range = 0.075, # randomly shift images vertivally (fraction of total heigth)\n",
    "        horizontal_flip = True, # randomly flip images\n",
    "        vertical_flip = False,\n",
    "        shear_range = 0.075,\n",
    "        fill_mode = 'constant',\n",
    "        cval = 0)\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 少量旋转\n",
    "- 少量偏移\n",
    "- 水平翻转\n",
    "- 垂直翻转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      " - 127s - loss: 1.1230 - acc: 0.5524 - val_loss: 1.4614 - val_acc: 0.5491\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.46135, saving model to ./models/lapel.best0420_InceptionV3.h5\n",
      "Epoch 2/16\n",
      " - 119s - loss: 0.7447 - acc: 0.7260 - val_loss: 1.3838 - val_acc: 0.5491\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.46135 to 1.38382, saving model to ./models/lapel.best0420_InceptionV3.h5\n",
      "Epoch 3/16\n",
      " - 129s - loss: 0.6228 - acc: 0.7697 - val_loss: 0.7900 - val_acc: 0.7231\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.38382 to 0.78999, saving model to ./models/lapel.best0420_InceptionV3.h5\n",
      "Epoch 4/16\n",
      " - 122s - loss: 0.5483 - acc: 0.8013 - val_loss: 0.7902 - val_acc: 0.7444\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/16\n",
      " - 122s - loss: 0.4975 - acc: 0.8204 - val_loss: 0.9419 - val_acc: 0.7101\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/16\n",
      " - 119s - loss: 0.4651 - acc: 0.8333 - val_loss: 0.7711 - val_acc: 0.7550\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.78999 to 0.77112, saving model to ./models/lapel.best0420_InceptionV3.h5\n",
      "Epoch 7/16\n",
      " - 117s - loss: 0.4082 - acc: 0.8532 - val_loss: 1.3555 - val_acc: 0.6355\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/16\n",
      " - 120s - loss: 0.3897 - acc: 0.8635 - val_loss: 0.8863 - val_acc: 0.7290\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/16\n",
      " - 119s - loss: 0.3495 - acc: 0.8767 - val_loss: 0.5822 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.77112 to 0.58221, saving model to ./models/lapel.best0420_InceptionV3.h5\n",
      "Epoch 10/16\n",
      " - 118s - loss: 0.3316 - acc: 0.8826 - val_loss: 0.6475 - val_acc: 0.7846\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/16\n",
      " - 117s - loss: 0.3284 - acc: 0.8824 - val_loss: 0.7367 - val_acc: 0.7728\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/16\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./models/{0}.best0420_InceptionV3.h5'.format(prefix_cls), verbose=1, \n",
    "                               save_best_only=True, save_weights_only=True, mode='val_acc')\n",
    "\n",
    "try:\n",
    "    # Fit the model\n",
    "    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                                  epochs=epochs, validation_data=(X_valid, y_valid),\n",
    "                                  verbose=2, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                                  callbacks=[EarlyStopping(patience=5), checkpointer])\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = InceptionV3(include_top=False, input_shape=(width, width, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((width, width, 3))\n",
    "\n",
    "x = inputs\n",
    "x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "x = cnn_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./models/{}.best0420_InceptionV3.h5'.format(prefix_cls)) #加载以前训练好的模型，继续测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "adam = Adam(lr=0.0001) \n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Set a learning rate annealer\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "#                                             patience=3,\n",
    "#                                             verbose=1,\n",
    "#                                             factor=0.1,\n",
    "#                                             min_lr=0.00001)\n",
    "epochs = 16\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      " - 123s - loss: 0.2049 - acc: 0.9275 - val_loss: 0.4564 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45636, saving model to ./models/lapel.best0420_InceptionV3.h5\n",
      "Epoch 2/16\n",
      " - 120s - loss: 0.1489 - acc: 0.9480 - val_loss: 0.3952 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45636 to 0.39517, saving model to ./models/lapel.best0420_InceptionV3.h5\n",
      "Epoch 3/16\n",
      " - 119s - loss: 0.1107 - acc: 0.9626 - val_loss: 0.4158 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/16\n",
      " - 120s - loss: 0.0880 - acc: 0.9687 - val_loss: 0.4246 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/16\n"
     ]
    }
   ],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./models/{0}.best0420_InceptionV3.h5'.format(prefix_cls), verbose=1, \n",
    "                               save_best_only=True, mode='val_acc')\n",
    "\n",
    "try:\n",
    "    # Fit the model\n",
    "    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                                  epochs=epochs, validation_data=(X_valid, y_valid),\n",
    "                                  verbose=2, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                                  callbacks=[EarlyStopping(patience=5), checkpointer])\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/collar_design_labels/faad3490a16c7f3d4f...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/collar_design_labels/0b2b4254f35ce3a41a...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/collar_design_labels/7f2be608e06f804dd5...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/collar_design_labels/4b09d4dca80caac42e...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/collar_design_labels/de91f00a05e84d7239...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class\n",
       "0  Images/collar_design_labels/faad3490a16c7f3d4f...  collar_design_labels\n",
       "1  Images/collar_design_labels/0b2b4254f35ce3a41a...  collar_design_labels\n",
       "2  Images/collar_design_labels/7f2be608e06f804dd5...  collar_design_labels\n",
       "3  Images/collar_design_labels/4b09d4dca80caac42e...  collar_design_labels\n",
       "4  Images/collar_design_labels/de91f00a05e84d7239...  collar_design_labels"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./z_rank/Tests/question.csv', header=None)\n",
    "df_test.columns = ['image_id', 'class', 'x']\n",
    "del df_test['x']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lapel_design_labels: 1343\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/lapel_design_labels/518bcadaa97418d29c7...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/lapel_design_labels/156228a4743bfd86cef...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/lapel_design_labels/393f4962b5c2fbf42cb...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/lapel_design_labels/b5074c1b96f2402bab1...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/lapel_design_labels/5ce450fa7e3f1890cb0...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                class\n",
       "0  Images/lapel_design_labels/518bcadaa97418d29c7...  lapel_design_labels\n",
       "1  Images/lapel_design_labels/156228a4743bfd86cef...  lapel_design_labels\n",
       "2  Images/lapel_design_labels/393f4962b5c2fbf42cb...  lapel_design_labels\n",
       "3  Images/lapel_design_labels/b5074c1b96f2402bab1...  lapel_design_labels\n",
       "4  Images/lapel_design_labels/5ce450fa7e3f1890cb0...  lapel_design_labels"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_load = df_test[(df_test['class'] == cur_class)].copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "\n",
    "print('{0}: {1}'.format(cur_class, len(df_load)))\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./rank/Images/lapel_design_labels/518bcadaa97418d29c78a2f6dcff0209.jpg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'./rank/{0}'.format(df_load['image_id'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1343/1343 [00:08<00:00, 158.93it/s]\n"
     ]
    }
   ],
   "source": [
    "n = len(df_load)\n",
    "X_test = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    X_test[i] = cv2.resize(cv2.imread('./z_rank/{0}'.format(df_load['image_id'][i])), (width, width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./models/{}.best0420_InceptionV3.h5'.format(prefix_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_np = model.predict(X_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/lapel_design_labels/518bcadaa97418d29c7...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "      <td>0.0001;0.0000;0.9998;0.0000;0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/lapel_design_labels/156228a4743bfd86cef...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "      <td>0.1319;0.0347;0.7543;0.0695;0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/lapel_design_labels/393f4962b5c2fbf42cb...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "      <td>0.1873;0.3501;0.2292;0.2152;0.0183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/lapel_design_labels/b5074c1b96f2402bab1...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "      <td>0.0000;0.0000;0.0000;0.0001;0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/lapel_design_labels/5ce450fa7e3f1890cb0...</td>\n",
       "      <td>lapel_design_labels</td>\n",
       "      <td>0.9999;0.0000;0.0000;0.0000;0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                class  \\\n",
       "0  Images/lapel_design_labels/518bcadaa97418d29c7...  lapel_design_labels   \n",
       "1  Images/lapel_design_labels/156228a4743bfd86cef...  lapel_design_labels   \n",
       "2  Images/lapel_design_labels/393f4962b5c2fbf42cb...  lapel_design_labels   \n",
       "3  Images/lapel_design_labels/b5074c1b96f2402bab1...  lapel_design_labels   \n",
       "4  Images/lapel_design_labels/5ce450fa7e3f1890cb0...  lapel_design_labels   \n",
       "\n",
       "                               result  \n",
       "0  0.0001;0.0000;0.9998;0.0000;0.0000  \n",
       "1  0.1319;0.0347;0.7543;0.0695;0.0096  \n",
       "2  0.1873;0.3501;0.2292;0.2152;0.0183  \n",
       "3  0.0000;0.0000;0.0000;0.0001;0.9999  \n",
       "4  0.9999;0.0000;0.0000;0.0000;0.0000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for i, row in df_load.iterrows():\n",
    "    tmp_list = test_np[i]\n",
    "    tmp_result = ''\n",
    "    for tmp_ret in tmp_list:\n",
    "        tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        \n",
    "    result.append(tmp_result[:-1])\n",
    "\n",
    "df_load['result'] = result\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_load.to_csv('./result/{}_0421a.csv'.format(prefix_cls), header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_load = pd.read_csv('./result/{}_0421a.csv'.format(prefix_cls), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1343"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
