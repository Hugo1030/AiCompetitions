{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据\n",
    "-  label 文件一共有 79572 行\n",
    "- 各种维度混合在一起\n",
    "- 我们的目的是切分开各种维度, 进行训练和模拟\n",
    "- 那么首先取出个标签的图片进行聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/collar_design_labels/4d8a38b29930a403e5...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nnynn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/collar_design_labels/bd0981f231180d2b00...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/collar_design_labels/26937e1724feadfe39...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>ynnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/collar_design_labels/cf4140ec542887270f...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/collar_design_labels/50644b2b9de045f2d1...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class  \\\n",
       "0  Images/collar_design_labels/4d8a38b29930a403e5...  collar_design_labels   \n",
       "1  Images/collar_design_labels/bd0981f231180d2b00...  collar_design_labels   \n",
       "2  Images/collar_design_labels/26937e1724feadfe39...  collar_design_labels   \n",
       "3  Images/collar_design_labels/cf4140ec542887270f...  collar_design_labels   \n",
       "4  Images/collar_design_labels/50644b2b9de045f2d1...  collar_design_labels   \n",
       "\n",
       "   label  \n",
       "0  nnynn  \n",
       "1  nynnn  \n",
       "2  ynnnn  \n",
       "3  nynnn  \n",
       "4  nynnn  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./Annotations/label.csv', header=None)\n",
    "df_train.columns = ['image_id', 'class', 'label']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['collar_design_labels', 'neckline_design_labels', 'skirt_length_labels',\n",
    "          'sleeve_length_labels', 'neck_design_labels', 'coat_length_labels', 'lapel_design_labels',\n",
    "          'pant_length_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pant_length_labels: 7460\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/pant_length_labels/07264732b8dfa05ca485...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>ynnnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/pant_length_labels/ae01c534cddd89261c95...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>nnynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/pant_length_labels/7d51f1a23c93213e4652...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>nnnnny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/pant_length_labels/5c9f7c834ae1c1daa3f5...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>nynnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/pant_length_labels/e1eb7a176c228107125d...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>nnnnyn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id               class  \\\n",
       "0  Images/pant_length_labels/07264732b8dfa05ca485...  pant_length_labels   \n",
       "1  Images/pant_length_labels/ae01c534cddd89261c95...  pant_length_labels   \n",
       "2  Images/pant_length_labels/7d51f1a23c93213e4652...  pant_length_labels   \n",
       "3  Images/pant_length_labels/5c9f7c834ae1c1daa3f5...  pant_length_labels   \n",
       "4  Images/pant_length_labels/e1eb7a176c228107125d...  pant_length_labels   \n",
       "\n",
       "    label  \n",
       "0  ynnnnn  \n",
       "1  nnynnn  \n",
       "2  nnnnny  \n",
       "3  nynnnn  \n",
       "4  nnnnyn  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_class = classes[7]\n",
    "df_load = df_train[(df_train['class'] == cur_class)].copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "\n",
    "print('{0}: {1}'.format(cur_class, len(df_load)))\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(df_load)\n",
    "n_class = len(df_load['label'][0])\n",
    "width = 299 # 定义图片大小\n",
    "\n",
    "X = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "y = np.zeros((n, n_class), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Images/pant_length_labels/07264732b8dfa05ca4857c71d2f9fb4b.jpg\n"
     ]
    }
   ],
   "source": [
    "print('./{0}'.format(df_load['image_id'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7460/7460 [00:49<00:00, 151.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n)):\n",
    "    tmp_label = df_load['label'][i]\n",
    "    if len(tmp_label) > n_class:\n",
    "        print(df_load['image_id'][i])\n",
    "    X[i] = cv2.resize(cv2.imread('./{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "    y[i][tmp_label.find('y')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7460, 299, 299, 3), (7460, 6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(12, 7))\n",
    "#for i in range(8):\n",
    "#    random_index = random.randint(0, n-1)\n",
    "#    plt.subplot(2, 4, i+1)\n",
    "#    plt.imshow(X[random_index][:,:,::-1])\n",
    "#    plt.title(y[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.regularizers import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.regularizers import *\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = InceptionV3(include_top=False, input_shape=(width, width, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((width, width, 3))\n",
    "\n",
    "x = inputs\n",
    "x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "x = cnn_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pant'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "prefix_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练/测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6564, 299, 299, 3), (6564, 6))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.12, random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "adam = Adam(lr=0.001) \n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Set a learning rate annealer\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "#                                             patience=3,\n",
    "#                                             verbose=1,\n",
    "#                                             factor=0.1,\n",
    "#                                             min_lr=0.00001)\n",
    "epochs = 16\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center = False, # set input mean to 0 over the dataset\n",
    "        samplewise_center = False, # set each sample mean to 0\n",
    "        featurewise_std_normalization = False, # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization = False, # divide each input by its std\n",
    "        zca_whitening = False, # apply ZCA whitening\n",
    "        rotation_range = 10, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.05, # randomly zoom image\n",
    "        width_shift_range = 0.075, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range = 0.075, # randomly shift images vertivally (fraction of total heigth)\n",
    "        horizontal_flip = True, # randomly flip images\n",
    "        vertical_flip = False,\n",
    "        shear_range = 0.075,\n",
    "        fill_mode = 'constant',\n",
    "        cval = 0)\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 少量旋转\n",
    "- 少量偏移\n",
    "- 水平翻转\n",
    "- 垂直翻转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      " - 133s - loss: 1.0844 - acc: 0.5845 - val_loss: 2.1303 - val_acc: 0.4821\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.13029, saving model to ./models/pant.best0420_InceptionV3.h5\n",
      "Epoch 2/16\n",
      " - 127s - loss: 0.7450 - acc: 0.7255 - val_loss: 0.7877 - val_acc: 0.7254\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.13029 to 0.78769, saving model to ./models/pant.best0420_InceptionV3.h5\n",
      "Epoch 3/16\n",
      " - 129s - loss: 0.6687 - acc: 0.7532 - val_loss: 0.7091 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.78769 to 0.70912, saving model to ./models/pant.best0420_InceptionV3.h5\n",
      "Epoch 4/16\n",
      " - 128s - loss: 0.5780 - acc: 0.7829 - val_loss: 0.7647 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/16\n",
      " - 127s - loss: 0.5609 - acc: 0.7986 - val_loss: 0.5792 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.70912 to 0.57915, saving model to ./models/pant.best0420_InceptionV3.h5\n",
      "Epoch 6/16\n",
      " - 125s - loss: 0.5264 - acc: 0.8105 - val_loss: 0.6251 - val_acc: 0.7902\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/16\n",
      " - 125s - loss: 0.4847 - acc: 0.8218 - val_loss: 0.5092 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.57915 to 0.50922, saving model to ./models/pant.best0420_InceptionV3.h5\n",
      "Epoch 8/16\n",
      " - 124s - loss: 0.4407 - acc: 0.8339 - val_loss: 0.6575 - val_acc: 0.7768\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/16\n",
      " - 124s - loss: 0.4310 - acc: 0.8431 - val_loss: 0.6393 - val_acc: 0.7801\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/16\n",
      " - 125s - loss: 0.3999 - acc: 0.8521 - val_loss: 0.5950 - val_acc: 0.7991\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/16\n",
      " - 126s - loss: 0.3723 - acc: 0.8602 - val_loss: 0.5104 - val_acc: 0.8203\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/16\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./models/{0}.best0420_InceptionV3.h5'.format(prefix_cls), verbose=1, \n",
    "                               save_best_only=True, save_weights_only=True, mode='val_acc')\n",
    "\n",
    "try:\n",
    "    # Fit the model\n",
    "    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                                  epochs=epochs, validation_data=(X_valid, y_valid),\n",
    "                                  verbose=2, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                                  callbacks=[EarlyStopping(patience=5), checkpointer])\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = InceptionV3(include_top=False, input_shape=(width, width, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((width, width, 3))\n",
    "\n",
    "x = inputs\n",
    "x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "x = cnn_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./models/{}.best0420_InceptionV3.h5'.format(prefix_cls)) #加载以前训练好的模型，继续测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "adam = Adam(lr=0.0001) \n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Set a learning rate annealer\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "#                                             patience=3,\n",
    "#                                             verbose=1,\n",
    "#                                             factor=0.1,\n",
    "#                                             min_lr=0.00001)\n",
    "epochs = 16\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      " - 134s - loss: 0.3299 - acc: 0.8785 - val_loss: 0.3463 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.34627, saving model to ./models/pant.best0420_InceptionV3.h5\n",
      "Epoch 2/16\n",
      " - 129s - loss: 0.2564 - acc: 0.9024 - val_loss: 0.3323 - val_acc: 0.8728\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.34627 to 0.33229, saving model to ./models/pant.best0420_InceptionV3.h5\n",
      "Epoch 3/16\n",
      " - 127s - loss: 0.2321 - acc: 0.9157 - val_loss: 0.3587 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/16\n",
      " - 126s - loss: 0.1989 - acc: 0.9244 - val_loss: 0.3530 - val_acc: 0.8817\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/16\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./models/{0}.best0420_InceptionV3.h5'.format(prefix_cls), verbose=1, \n",
    "                               save_best_only=True, mode='val_acc')\n",
    "\n",
    "try:\n",
    "    # Fit the model\n",
    "    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                                  epochs=epochs, validation_data=(X_valid, y_valid),\n",
    "                                  verbose=2, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                                  callbacks=[EarlyStopping(patience=5), checkpointer])\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/collar_design_labels/faad3490a16c7f3d4f...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/collar_design_labels/0b2b4254f35ce3a41a...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/collar_design_labels/7f2be608e06f804dd5...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/collar_design_labels/4b09d4dca80caac42e...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/collar_design_labels/de91f00a05e84d7239...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class\n",
       "0  Images/collar_design_labels/faad3490a16c7f3d4f...  collar_design_labels\n",
       "1  Images/collar_design_labels/0b2b4254f35ce3a41a...  collar_design_labels\n",
       "2  Images/collar_design_labels/7f2be608e06f804dd5...  collar_design_labels\n",
       "3  Images/collar_design_labels/4b09d4dca80caac42e...  collar_design_labels\n",
       "4  Images/collar_design_labels/de91f00a05e84d7239...  collar_design_labels"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./z_rank/Tests/question.csv', header=None)\n",
    "df_test.columns = ['image_id', 'class', 'x']\n",
    "del df_test['x']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pant_length_labels: 1434\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/pant_length_labels/e78538758763e84e9700...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/pant_length_labels/1e680886dd3d65882745...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/pant_length_labels/7e25106e7a0f5ac5d26a...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/pant_length_labels/53fa07f57908d258f4ba...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/pant_length_labels/737319237b262a9515a5...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id               class\n",
       "0  Images/pant_length_labels/e78538758763e84e9700...  pant_length_labels\n",
       "1  Images/pant_length_labels/1e680886dd3d65882745...  pant_length_labels\n",
       "2  Images/pant_length_labels/7e25106e7a0f5ac5d26a...  pant_length_labels\n",
       "3  Images/pant_length_labels/53fa07f57908d258f4ba...  pant_length_labels\n",
       "4  Images/pant_length_labels/737319237b262a9515a5...  pant_length_labels"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_load = df_test[(df_test['class'] == cur_class)].copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "\n",
    "print('{0}: {1}'.format(cur_class, len(df_load)))\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./z_rank/Images/pant_length_labels/e78538758763e84e97009dda11754b47.jpg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'./z_rank/{0}'.format(df_load['image_id'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1434/1434 [00:08<00:00, 174.98it/s]\n"
     ]
    }
   ],
   "source": [
    "n = len(df_load)\n",
    "X_test = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    X_test[i] = cv2.resize(cv2.imread('./z_rank/{0}'.format(df_load['image_id'][i])), (width, width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./models/{}.best0420_InceptionV3.h5'.format(prefix_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_np = model.predict(X_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1434, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/pant_length_labels/e78538758763e84e9700...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>0.0000;0.0000;0.0000;0.0394;0.4119;0.5486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/pant_length_labels/1e680886dd3d65882745...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>0.0062;0.0054;0.9855;0.0028;0.0001;0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/pant_length_labels/7e25106e7a0f5ac5d26a...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>0.0967;0.0045;0.1461;0.4598;0.1608;0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/pant_length_labels/53fa07f57908d258f4ba...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>0.0002;0.0001;0.0004;0.9885;0.0096;0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/pant_length_labels/737319237b262a9515a5...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>0.0000;0.0000;0.0000;0.0007;0.0834;0.9158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id               class  \\\n",
       "0  Images/pant_length_labels/e78538758763e84e9700...  pant_length_labels   \n",
       "1  Images/pant_length_labels/1e680886dd3d65882745...  pant_length_labels   \n",
       "2  Images/pant_length_labels/7e25106e7a0f5ac5d26a...  pant_length_labels   \n",
       "3  Images/pant_length_labels/53fa07f57908d258f4ba...  pant_length_labels   \n",
       "4  Images/pant_length_labels/737319237b262a9515a5...  pant_length_labels   \n",
       "\n",
       "                                      result  \n",
       "0  0.0000;0.0000;0.0000;0.0394;0.4119;0.5486  \n",
       "1  0.0062;0.0054;0.9855;0.0028;0.0001;0.0000  \n",
       "2  0.0967;0.0045;0.1461;0.4598;0.1608;0.1320  \n",
       "3  0.0002;0.0001;0.0004;0.9885;0.0096;0.0013  \n",
       "4  0.0000;0.0000;0.0000;0.0007;0.0834;0.9158  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for i, row in df_load.iterrows():\n",
    "    tmp_list = test_np[i]\n",
    "    tmp_result = ''\n",
    "    for tmp_ret in tmp_list:\n",
    "        tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        \n",
    "    result.append(tmp_result[:-1])\n",
    "\n",
    "df_load['result'] = result\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_load.to_csv('./result/{}_0421a.csv'.format(prefix_cls), header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_load = pd.read_csv('./result/{}_0421a.csv'.format(prefix_cls), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1434"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
