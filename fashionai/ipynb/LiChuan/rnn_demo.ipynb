{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.2\n",
      "IPython 6.1.0\n",
      "\n",
      "tensorflow 1.3.0\n",
      "numpy 1.13.3\n",
      "\n",
      "compiler   : GCC 4.2.1 (Apple Inc. build 5666) (dot 3)\n",
      "system     : Darwin\n",
      "release    : 17.2.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "# 示例代码运行环境\n",
    "%load_ext watermark\n",
    "%watermark -p tensorflow,numpy -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Demo (Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assume input and state are 128-length vector\n",
    "class RNNCell:\n",
    "    def __init__(self, input_size, state_size):\n",
    "        self.W = np.random.rand(input_size, state_size)\n",
    "        self.U = np.random.rand(state_size, state_size)\n",
    "        self.b = np.zeros((1, state_size))\n",
    "        \n",
    "    def forward(self, input_, state):\n",
    "        return input_.dot(self.W) + state.dot(self.U) + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNNCell(128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input0 = np.random.rand(1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n"
     ]
    }
   ],
   "source": [
    "state0 = np.zeros((1, 128))\n",
    "state1 = rnn.forward(input0, state0)\n",
    "print(state1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n"
     ]
    }
   ],
   "source": [
    "input1 = np.random.rand(1, 128)\n",
    "state2 = rnn.forward(input1, state1)\n",
    "print(state2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Demo (Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "word_embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(list(chunks(range(30), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [12 13 14]\n",
      " [15 16 17]\n",
      " [18 19 20]\n",
      " [21 22 23]\n",
      " [24 25 26]\n",
      " [27 28 29]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_embeds = tf.nn.embedding_lookup(word_embedding, data[:, [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'rnn/transpose:0' shape=(10, 2, 128) dtype=float32>, <tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 128) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "output, states = tf.nn.dynamic_rnn(cell, input_embeds, dtype=tf.float32)\n",
    "print(output, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_flat = tf.reshape(output, (-1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 128)\n",
      "(10, 2, 128)\n",
      "(20, 128)\n",
      "(10, 128)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_val = output.eval()\n",
    "    states_val = states.eval()\n",
    "    print(output_flat.eval().shape)\n",
    "    print(output_val.shape)\n",
    "    print(output_val.reshape((-1, 128)).shape)\n",
    "    print(states_val.shape)\n",
    "    print((output_val[:,1,:] == states_val).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Demo（处理变长数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [[1, 2], [1, 2, 3], [1, 2, 3, 4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [1, 2, 3], [1, 2, 3, 4, 5]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_padding = np.asarray([[1, 2, 0, 0, 0], [1, 2, 3, 0, 0], [1, 2, 3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0],\n",
       "       [1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding 的问题:\n",
    "1. RNN 进化到一个『不对』的状态\n",
    "2. 最长的句子可能很长，影响性能\n",
    "3. 损失函数没法安排，多了很多『假』Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "vocab_size = 100\n",
    "word_embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(128)\n",
    "word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeds = tf.nn.embedding_lookup(word_embedding, data_padding[:, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0, 0],\n",
       "       [1, 2, 3, 0],\n",
       "       [1, 2, 3, 4]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_padding[:, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 0 0]\n",
      " [1 2 3 0]\n",
      " [1 2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "print(data_padding[:, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output, states = tf.nn.dynamic_rnn(cell, input_embeds, dtype=tf.float32, sequence_length=[2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "区别是上面的代码加上了 sequence_length 参数。该参数是一个一维 Tensor（因此可以随着 batch 数据变化），对每个样本，超过其对应 sequence_length 之后 dynamic_rnn 不会实际去做 state 计算，而是直接复制上一个 state，超长的对应 output 则设置为 0 向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数的解决\n",
    "根据上面的解释我们知道可以让 dynamic_rnn 在超长之后不做实际计算，这时候超长的部分 output 会输出 0。但是这些 output 依然会和 label 进行计算，产生 cost，进而影响模型的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0],\n",
       "       [2, 3, 0, 0],\n",
       "       [2, 3, 4, 5]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_padding[:, 1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面是我们这个 RNN Language model 对应的 labels，我们如何让 0 的部分不计入损失呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 1 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "labels = tf.reshape(data_padding[:, 1:5], [-1])\n",
    "mask = tf.sign(labels)\n",
    "with tf.Session() as sess:\n",
    "    print(mask.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把原来的 cost 和 mask 函数相乘，作为新的 cost 给优化器进行优化，即可忽略这些无用的 labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用于生成时的一些提示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cell 的 zero_state 函数可以产生该 cell 的初始状态（对 BasicRNNCell 来说就是一个 0 矩阵）\n",
    "cell 本身也可以调用 (Python 里的 __call__ 方法，用于产生单步的状态变化\n",
    "\n",
    "tf.slice 可以用于取 tensor 的某一列等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "vocab_size = 100\n",
    "word_embedding_dim = 128\n",
    "word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))\n",
    "input_embeds = tf.nn.embedding_lookup(word_embedding, data_padding[:, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(4), Dimension(128)])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "## 取第一个词\n",
    "single_input_embeds = tf.slice(input_embeds, [0, 0, 0], [3, 1, 128])\n",
    "print(single_input_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 走一步\n",
    "output, state = cell(tf.reshape(single_input_embeds, (3, 128)), cell.zero_state(3, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_val = output.eval()\n",
    "    state_val = state.eval()\n",
    "    print((output_val == state_val).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
