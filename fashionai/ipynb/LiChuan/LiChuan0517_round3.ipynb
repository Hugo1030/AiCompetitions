{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 将 round2 模型里面训练集中预测错误的图片, 和验证集图片找出来 valid_error\n",
    "     * 加载训练集, 未经过预处理\n",
    "     * 加载验证集\n",
    "     * 使用模型进行预测, 得到错误预测的 X_error, y_error \n",
    "* 对 valid_error 做数据增强, 放入 /valid_error/label/ 文件夹\n",
    "* 使用这个数据, 对模型进行第三轮的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/collar_design_labels/0ef580b4deabcd9fa4...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>ynnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/collar_design_labels/87ccc33937821a97ad...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nnynn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/collar_design_labels/26caac7d1f1b36fb9d...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>ynnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/collar_design_labels/396ab4e7cbc6798100...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/collar_design_labels/fc4a679c2bf209de13...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>ynnnn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class  \\\n",
       "0  Images/collar_design_labels/0ef580b4deabcd9fa4...  collar_design_labels   \n",
       "1  Images/collar_design_labels/87ccc33937821a97ad...  collar_design_labels   \n",
       "2  Images/collar_design_labels/26caac7d1f1b36fb9d...  collar_design_labels   \n",
       "3  Images/collar_design_labels/396ab4e7cbc6798100...  collar_design_labels   \n",
       "4  Images/collar_design_labels/fc4a679c2bf209de13...  collar_design_labels   \n",
       "\n",
       "   label  \n",
       "0  ynnnn  \n",
       "1  nnynn  \n",
       "2  ynnnn  \n",
       "3  nynnn  \n",
       "4  ynnnn  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train/Annotations/label.csv')\n",
    "df_train.columns = ['image_id', 'class', 'label']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['collar_design_labels', 'neckline_design_labels', 'skirt_length_labels',\n",
    "          'sleeve_length_labels', 'neck_design_labels', 'coat_length_labels', 'lapel_design_labels',\n",
    "          'pant_length_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleeve_length_labels: 17285\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/sleeve_length_labels/f5c414bda8a9bb97f6...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "      <td>nnnnnnmym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/sleeve_length_labels/ffeef43a34d68b2a47...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "      <td>nnynnnnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/sleeve_length_labels/4be61ca727ad25645e...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "      <td>nnnnnnmmy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/sleeve_length_labels/b9d69a26db06295bfa...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "      <td>nnnynnnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/sleeve_length_labels/fb7c3a0181d538b52e...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "      <td>nnnnnnynn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class  \\\n",
       "0  Images/sleeve_length_labels/f5c414bda8a9bb97f6...  sleeve_length_labels   \n",
       "1  Images/sleeve_length_labels/ffeef43a34d68b2a47...  sleeve_length_labels   \n",
       "2  Images/sleeve_length_labels/4be61ca727ad25645e...  sleeve_length_labels   \n",
       "3  Images/sleeve_length_labels/b9d69a26db06295bfa...  sleeve_length_labels   \n",
       "4  Images/sleeve_length_labels/fb7c3a0181d538b52e...  sleeve_length_labels   \n",
       "\n",
       "       label  \n",
       "0  nnnnnnmym  \n",
       "1  nnynnnnnn  \n",
       "2  nnnnnnmmy  \n",
       "3  nnnynnnnn  \n",
       "4  nnnnnnynn  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_class = classes[3]\n",
    "prefix_cls = cur_class.split('_')[0]\n",
    "\n",
    "df_load = df_train[(df_train['class'] == cur_class)].copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "\n",
    "print('{0}: {1}'.format(cur_class, len(df_load)))\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_ration=0.9\n",
    "valid_data=df_load[int(n_ration*len(df_load)):]\n",
    "df_load=df_load[:int(n_ration*len(df_load))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(df_load)\n",
    "n_class = len(df_load['label'][0])\n",
    "width = 299 # 定义图片大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "y_train = np.zeros((n, n_class), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15556/15556 [01:31<00:00, 170.49it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n)):\n",
    "    tmp_label = df_load['label'][i]\n",
    "    X_train[i] = cv2.resize(cv2.imread('./data/train/{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "    y_train[i][tmp_label.find('y')] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 重置索引\n",
    "valid_data = valid_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(valid_data)\n",
    "n_class = len(valid_data['label'][0])\n",
    "width = 299 # 定义图片大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "y_valid = np.zeros((n, n_class), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1729/1729 [00:09<00:00, 173.49it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n)):\n",
    "    tmp_label = valid_data['label'][i]\n",
    "    X_valid[i] = cv2.resize(cv2.imread('./data/train/{0}'.format(valid_data['image_id'][i])), (width, width))\n",
    "    y_valid[i][tmp_label.find('y')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15556, 299, 299, 3), (15556, 9), (1729, 299, 299, 3), (1729, 9))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.regularizers import *\n",
    "from keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = InceptionResNetV2(include_top=False, input_shape=(width, width, 3), weights='imagenet')\n",
    "inputs = Input((width, width, 3))\n",
    "\n",
    "x = inputs\n",
    "x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "x = cnn_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "prefix_cls = cur_class.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./models/{}.best0516b_InceptionResNetV2_round2.h5'.format(prefix_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_train)\n",
    "\n",
    "# Convert predictions classes to one hot vectors\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Display some error results\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_train[errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncols = 2\n",
    "def display_errors(errors_index, img_errors, pred_errors, obs_errors):\n",
    "    \"\"\"This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows, ncols, sharex=True, sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row, col].imshow((img_errors[error]).reshape((299, 299, 3)))\n",
    "            ax[row, col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error], obs_errors[error]))\n",
    "            n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors, axis=1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors\n",
    "most_imaportant_errors = sorted_dela_errors[-nrows*ncols:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_imaportant_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找出错误图片编号, 并与 valid 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_errors = df_load[errors]\n",
    "\n",
    "df_temp = pd.concat([df_errors, valid_data])\n",
    "\n",
    "# 重置索引\n",
    "df_temp = df_temp.reset_index(drop=True)\n",
    "\n",
    "df_temp.to_csv('./valid_error/{}_valid_errors.csv'.format(prefix_cls), header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对 valid_error 做数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix_cls = cur_class.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/sleeve_length_labels/4be61ca727ad25645e...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "      <td>nnnnnnmmy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/sleeve_length_labels/28c823bbcd13f81e7f...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "      <td>nnnnmynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/sleeve_length_labels/4480385f3cfb87a3fd...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "      <td>nnnnnnmmy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/sleeve_length_labels/25294867fc2cf4fdd7...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "      <td>nnnnnnnny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/sleeve_length_labels/880fa1a43b0496eb5c...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "      <td>nnnnnnmmy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class  \\\n",
       "0  Images/sleeve_length_labels/4be61ca727ad25645e...  sleeve_length_labels   \n",
       "1  Images/sleeve_length_labels/28c823bbcd13f81e7f...  sleeve_length_labels   \n",
       "2  Images/sleeve_length_labels/4480385f3cfb87a3fd...  sleeve_length_labels   \n",
       "3  Images/sleeve_length_labels/25294867fc2cf4fdd7...  sleeve_length_labels   \n",
       "4  Images/sleeve_length_labels/880fa1a43b0496eb5c...  sleeve_length_labels   \n",
       "\n",
       "       label  \n",
       "0  nnnnnnmmy  \n",
       "1  nnnnmynnn  \n",
       "2  nnnnnnmmy  \n",
       "3  nnnnnnnny  \n",
       "4  nnnnnnmmy  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.read_csv('./valid_error/{}_valid_errors.csv'.format(prefix_cls))\n",
    "df_temp.columns = ['image_id', 'class', 'label']\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import data, img_as_float\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def mkdir_if_not_exist(path):\n",
    "    if not os.path.exists(os.path.join(*path)):\n",
    "        os.makedirs(os.path.join(*path))\n",
    "        \n",
    "mkdir_if_not_exist(['./data/valid_error/Images/{}/'.format(cur_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images have preprocessed.\n",
      "200 images have preprocessed.\n",
      "300 images have preprocessed.\n",
      "400 images have preprocessed.\n",
      "500 images have preprocessed.\n",
      "600 images have preprocessed.\n",
      "700 images have preprocessed.\n",
      "800 images have preprocessed.\n",
      "900 images have preprocessed.\n",
      "1000 images have preprocessed.\n",
      "1100 images have preprocessed.\n",
      "1200 images have preprocessed.\n",
      "1300 images have preprocessed.\n",
      "1400 images have preprocessed.\n",
      "1500 images have preprocessed.\n",
      "1600 images have preprocessed.\n",
      "1700 images have preprocessed.\n",
      "1800 images have preprocessed.\n",
      "1900 images have preprocessed.\n",
      "2000 images have preprocessed.\n",
      "2100 images have preprocessed.\n",
      "2200 images have preprocessed.\n",
      "2300 images have preprocessed.\n",
      "2400 images have preprocessed.\n",
      "2500 images have preprocessed.\n",
      "2600 images have preprocessed.\n",
      "2700 images have preprocessed.\n",
      "2800 images have preprocessed.\n",
      "2900 images have preprocessed.\n",
      "3000 images have preprocessed.\n",
      "3100 images have preprocessed.\n",
      "3200 images have preprocessed.\n",
      "3300 images have preprocessed.\n",
      "3400 images have preprocessed.\n",
      "3500 images have preprocessed.\n",
      "3600 images have preprocessed.\n",
      "3700 images have preprocessed.\n",
      "3800 images have preprocessed.\n",
      "3900 images have preprocessed.\n",
      "4000 images have preprocessed.\n",
      "4100 images have preprocessed.\n",
      "4200 images have preprocessed.\n"
     ]
    }
   ],
   "source": [
    "rootdir = './data/train/'\n",
    "outdir = './data/valid_error/Images/{}/'.format(cur_class)\n",
    "m = 0\n",
    "for i in range(n):\n",
    "    currentPath = rootdir + df_temp['image_id'][i]\n",
    "    filename = df_temp['image_id'][i].split('/')[-1]\n",
    "    \n",
    "    # 先填充, 再缩放\n",
    "    img = cv2.imread(currentPath)\n",
    "    dst0 = cv2.resize(img, (299, 299), interpolation=cv2.INTER_AREA)\n",
    "    rows,cols,channels = dst0.shape\n",
    "    \n",
    "    # 水平翻转\n",
    "    dst1 = cv2.flip(dst0, 1)\n",
    "    \n",
    "#     # 高斯噪声\n",
    "#     dst0.astype(\"float\")\n",
    "#     Gauss_noise = np.random.normal(0, 20, (rows, cols, channels))\n",
    "#     dst2 = dst0 + Gauss_noise\n",
    "#     dst2 = np.where(dst2 < 0, 0, np.where(dst2 > 255, 255, dst2))\n",
    "    \n",
    "#     # 顺时针旋转 5°/ 放大 5%\n",
    "#     M1 = cv2.getRotationMatrix2D((cols/2,rows/2),5,1) \n",
    "#     M2 = cv2.getRotationMatrix2D((cols/2,rows/2),0,1.05) \n",
    "#     dst3 = cv2.warpAffine(dst0,M1,(cols,rows))\n",
    "#     dst4 = cv2.warpAffine(dst0,M2,(cols,rows))\n",
    "    \n",
    "#     # 直方图\n",
    "#     dst5 = exposure.equalize_hist(dst0)*255\n",
    "    \n",
    "    cv2.imwrite(outdir + filename + \"-0.jpg\", dst0)\n",
    "    cv2.imwrite(outdir + filename + \"-1.jpg\", dst1)\n",
    "#     cv2.imwrite(outdir + filename + \"-2.jpg\", dst2.astype(\"uint8\"))\n",
    "#     cv2.imwrite(outdir + filename + \"-3.jpg\", dst3)\n",
    "#     cv2.imwrite(outdir + filename + \"-4.jpg\", dst4)\n",
    "#     cv2.imwrite(outdir + filename + \"-5.jpg\", dst5)  \n",
    "    \n",
    "    m += 1\n",
    "    if m%100 == 0:\n",
    "        print('{} images have preprocessed.'.format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(df_temp)\n",
    "n_class = len(df_temp['label'][0])\n",
    "width = 299 # 定义图片大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.zeros((n*2, width, width, 3), dtype=np.uint8)\n",
    "y_train = np.zeros((n*2, n_class), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4215/4215 [00:10<00:00, 406.26it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n)):\n",
    "    tmp_label = df_temp['label'][i]\n",
    "    for j in range(2):\n",
    "        X_train[i*2+j] = cv2.resize(cv2.imread('./data/valid_error/{0}'.format(df_temp['image_id'][i] + \"-%s.jpg\"%j)), (width, width))\n",
    "        y_train[i*2+j][tmp_label.find('y')] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.regularizers import *\n",
    "from keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = InceptionResNetV2(include_top=False, input_shape=(width, width, 3), weights='imagenet')\n",
    "inputs = Input((width, width, 3))\n",
    "\n",
    "x = inputs\n",
    "x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "x = cnn_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.00005)\n",
    "prefix_cls = cur_class.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('./models/{}.best0516b_InceptionResNetV2_round2.h5'.format(prefix_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8430 samples, validate on 1729 samples\n",
      "Epoch 1/2\n",
      "8430/8430 [==============================] - 340s 40ms/step - loss: 1.6386 - acc: 0.3539 - val_loss: 0.9652 - val_acc: 0.6669\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.96524, saving model to ./models/sleeve.best0517a_InceptionResNetV2_round3.h5\n",
      "Epoch 2/2\n",
      "8430/8430 [==============================] - 291s 35ms/step - loss: 0.8224 - acc: 0.6943 - val_loss: 0.4495 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.96524 to 0.44954, saving model to ./models/sleeve.best0517a_InceptionResNetV2_round3.h5\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./models/{0}.best0517a_InceptionResNetV2_round3.h5'.format(prefix_cls), verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "try:\n",
    "    h = model.fit(X_train, y_train, batch_size=32, epochs=2, \n",
    "                  callbacks=[EarlyStopping(patience=3), checkpointer], \n",
    "                  shuffle=True, \n",
    "                  validation_data=(X_valid, y_valid))\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906/906 [==============================] - 9s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005291031291153258, 1.0]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_valid, y=y_valid, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理图片进行全部预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir_if_not_exist(['./data/test-preprocessing/Images/{}/'.format(cur_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images have preprocessed.\n",
      "200 images have preprocessed.\n",
      "300 images have preprocessed.\n",
      "400 images have preprocessed.\n",
      "500 images have preprocessed.\n",
      "600 images have preprocessed.\n",
      "700 images have preprocessed.\n",
      "800 images have preprocessed.\n",
      "900 images have preprocessed.\n",
      "1000 images have preprocessed.\n",
      "1100 images have preprocessed.\n",
      "1200 images have preprocessed.\n",
      "1300 images have preprocessed.\n",
      "1400 images have preprocessed.\n",
      "1500 images have preprocessed.\n"
     ]
    }
   ],
   "source": [
    "rootdir = './data/week-rank/Images/{}'.format(cur_class)  # 指明被遍历的文件夹\n",
    "m = 0\n",
    "outdir = './data/test-preprocessing/Images/{}/'.format(cur_class)\n",
    "\n",
    "for parent, dirnames, filenames in os.walk(rootdir):\n",
    "    for filename in filenames:\n",
    "        currentPath = os.path.join(parent, filename)\n",
    "\n",
    "        # 先填充, 再缩放\n",
    "        img = cv2.imread(currentPath)\n",
    "        dst0 = cv2.resize(img, (299, 299), interpolation=cv2.INTER_AREA)\n",
    "        rows,cols,channels = dst0.shape\n",
    "\n",
    "#         # 顺时针旋转 5°/ 放大 5%\n",
    "#         M1 = cv2.getRotationMatrix2D((cols/2,rows/2),5,1) \n",
    "#         M2 = cv2.getRotationMatrix2D((cols/2,rows/2),0,1.05) \n",
    "#         dst1 = cv2.warpAffine(dst0,M1,(cols,rows))\n",
    "#         dst2 = cv2.warpAffine(dst0,M2,(cols,rows))\n",
    "        \n",
    "#         # 向下平移 0.2\n",
    "#         M3 = np.float32([[1,0,0],[0,1,int(cols*0.2)]])\n",
    "#         dst3 = cv2.warpAffine(dst0,M3,(cols,rows))\n",
    "        \n",
    "        # 水平翻转\n",
    "        dst1 = cv2.flip(dst0, 1)\n",
    "        \n",
    "        # 高斯噪声\n",
    "        dst0.astype(\"float\")\n",
    "        Gauss_noise = np.random.normal(0, 20, (rows, cols, channels))\n",
    "        dst2 = dst0 + Gauss_noise\n",
    "        dst2 = np.where(dst2 < 0, 0, np.where(dst2 > 255, 255, dst2))\n",
    "        \n",
    "#         # 对翻转后图片, 左右旋转 20°\n",
    "#         M4 = cv2.getRotationMatrix2D((cols/2,rows/2),20,1)\n",
    "#         M5 = cv2.getRotationMatrix2D((cols/2,rows/2),-20,1)\n",
    "#         dst5 = cv2.warpAffine(dst4,M4,(cols,rows))\n",
    "#         dst6 = cv2.warpAffine(dst4,M5,(cols,rows))\n",
    "        \n",
    "#         # 翻转后向下平移 0.2\n",
    "#         M6 = np.float32([[1,0,0],[0,1,int(cols*0.2)]])\n",
    "#         dst7 = cv2.warpAffine(dst4,M6,(cols,rows))\n",
    "        \n",
    "        cv2.imwrite(outdir + filename + \"-0.jpg\", dst0)\n",
    "        cv2.imwrite(outdir + filename + \"-1.jpg\", dst1)\n",
    "        cv2.imwrite(outdir + filename + \"-2.jpg\", dst2.astype(\"uint8\"))\n",
    "#         cv2.imwrite(outdir + filename + \"-3.jpg\", dst3)\n",
    "#         cv2.imwrite(outdir + filename + \"-4.jpg\", dst4.astype(\"uint8\"))\n",
    "#         cv2.imwrite(outdir + filename + \"-5.jpg\", dst5)\n",
    "#         cv2.imwrite(outdir + filename + \"-6.jpg\", dst6)\n",
    "#         cv2.imwrite(outdir + filename + \"-7.jpg\", dst7)\n",
    "        m += 1\n",
    "        if m%100 == 0:\n",
    "            print('{} images have preprocessed.'.format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/collar_design_labels/1078bc9a4fa91aef69...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/collar_design_labels/272c5d069581efc94f...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/collar_design_labels/2e67922d82216cc756...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/collar_design_labels/d9726ceee17c7ee811...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/collar_design_labels/1b7de7f9def99a5aa6...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class\n",
       "0  Images/collar_design_labels/1078bc9a4fa91aef69...  collar_design_labels\n",
       "1  Images/collar_design_labels/272c5d069581efc94f...  collar_design_labels\n",
       "2  Images/collar_design_labels/2e67922d82216cc756...  collar_design_labels\n",
       "3  Images/collar_design_labels/d9726ceee17c7ee811...  collar_design_labels\n",
       "4  Images/collar_design_labels/1b7de7f9def99a5aa6...  collar_design_labels"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./data/week-rank/Tests/question.csv', header=None)\n",
    "df_test.columns = ['image_id', 'class', 'x']\n",
    "del df_test['x']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleeve_length_labels: 2895\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/sleeve_length_labels/3a59bdc48834d4578e...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/sleeve_length_labels/a12e001f27c07365e6...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/sleeve_length_labels/ba5c56b7bc61711db3...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/sleeve_length_labels/efd82f9d354c0b2d53...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/sleeve_length_labels/1283a0ff4560bba965...</td>\n",
       "      <td>sleeve_length_labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class\n",
       "0  Images/sleeve_length_labels/3a59bdc48834d4578e...  sleeve_length_labels\n",
       "1  Images/sleeve_length_labels/a12e001f27c07365e6...  sleeve_length_labels\n",
       "2  Images/sleeve_length_labels/ba5c56b7bc61711db3...  sleeve_length_labels\n",
       "3  Images/sleeve_length_labels/efd82f9d354c0b2d53...  sleeve_length_labels\n",
       "4  Images/sleeve_length_labels/1283a0ff4560bba965...  sleeve_length_labels"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_load2 = df_test[(df_test['class'] == cur_class)].copy()\n",
    "df_load2.reset_index(inplace=True)\n",
    "del df_load2['index']\n",
    "\n",
    "print('{0}: {1}'.format(cur_class, len(df_load2)))\n",
    "df_load2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 2803/2895 [00:25<00:00, 109.76it/s]"
     ]
    }
   ],
   "source": [
    "n = len(df_load2)\n",
    "width = 299 # 定义图片大小\n",
    "X_test = np.zeros((n*3, width, width, 3), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    for j in range(3):\n",
    "        X_test[i*3+j] = cv2.resize(cv2.imread('./data/test-preprocessing/{0}'.format(df_load2['image_id'][i] + \"-%s.jpg\"%j)), (width, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('./models/{}.best0515a_InceptionResNetV2.h5'.format(prefix_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_np = model.predict(X_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 取同一张图片不同预处理方式的平均值\n",
    "result = []\n",
    "\n",
    "for i, row in df_load2.iterrows():\n",
    "    tmp_list = (test_np[i*3+0] + test_np[i*3+1] + test_np[i*3+2])/3\n",
    "    tmp_result = ''\n",
    "    for tmp_ret in tmp_list:\n",
    "        tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        \n",
    "    result.append(tmp_result[:-1])\n",
    "\n",
    "df_load2['result'] = result\n",
    "df_load2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_load2.to_csv('./result/{}_0517b_InceptionResNetV2.csv'.format(prefix_cls), header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
