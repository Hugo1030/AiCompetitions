{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据\n",
    "-  label 文件一共有 79572 行\n",
    "- 各种维度混合在一起\n",
    "- 我们的目的是切分开各种维度, 进行训练和模拟\n",
    "- 那么首先取出个标签的图片进行聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/collar_design_labels/4d8a38b29930a403e5...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nnynn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/collar_design_labels/bd0981f231180d2b00...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/collar_design_labels/26937e1724feadfe39...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>ynnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/collar_design_labels/cf4140ec542887270f...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/collar_design_labels/50644b2b9de045f2d1...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class  \\\n",
       "0  Images/collar_design_labels/4d8a38b29930a403e5...  collar_design_labels   \n",
       "1  Images/collar_design_labels/bd0981f231180d2b00...  collar_design_labels   \n",
       "2  Images/collar_design_labels/26937e1724feadfe39...  collar_design_labels   \n",
       "3  Images/collar_design_labels/cf4140ec542887270f...  collar_design_labels   \n",
       "4  Images/collar_design_labels/50644b2b9de045f2d1...  collar_design_labels   \n",
       "\n",
       "   label  \n",
       "0  nnynn  \n",
       "1  nynnn  \n",
       "2  ynnnn  \n",
       "3  nynnn  \n",
       "4  nynnn  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./Annotations/label.csv', header=None)\n",
    "df_train.columns = ['image_id', 'class', 'label']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['collar_design_labels', 'neckline_design_labels', 'skirt_length_labels',\n",
    "          'sleeve_length_labels', 'neck_design_labels', 'coat_length_labels', 'lapel_design_labels',\n",
    "          'pant_length_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_class = classes[4]\n",
    "df_load = df_train[(df_train['class'] == cur_class)].copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "\n",
    "print('{0}: {1}'.format(cur_class, len(df_load)))\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(df_load)\n",
    "n_class = len(df_load['label'][0])\n",
    "width = 299 # 定义图片大小\n",
    "\n",
    "X = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "y = np.zeros((n, n_class), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7034/7034 [00:40<00:00, 174.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n)):\n",
    "    tmp_label = df_load['label'][i]\n",
    "    if len(tmp_label) > n_class:\n",
    "        print(df_load['image_id'][i])\n",
    "    X[i] = cv2.resize(cv2.imread('./{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "    y[i][tmp_label.find('y')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.regularizers import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.regularizers import *\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = Xception(include_top=False, input_shape=(width, width, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((width, width, 3))\n",
    "\n",
    "x = inputs\n",
    "x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "x = cnn_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "prefix_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练/测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.12, random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "adam = Adam(lr=0.001) \n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Set a learning rate annealer\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "#                                             patience=3,\n",
    "#                                             verbose=1,\n",
    "#                                             factor=0.1,\n",
    "#                                             min_lr=0.00001)\n",
    "epochs = 32\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据增强\n",
    "--------------\n",
    "对训练数据增强\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center =False ,# set input mean to 0 over the dataset\n",
    "        samplewise_center = False ,# set each sample mean to 0\n",
    "        featurewise_std_normalization = False, # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization = False, # divide each input by its std\n",
    "        zca_whitening = False, # apply ZCA whitening\n",
    "        rotation_range = 10, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.3, # randomly zoom image\n",
    "        width_shift_range = 0.2, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range = 0.2, # randomly shift images vertivally (fraction of total heigth)\n",
    "        horizontal_flip = True, # randomly flip images\n",
    "        vertical_flip = False,\n",
    "        shear_range = 0.1,\n",
    "        fill_mode = 'constant',\n",
    "        cval = 0)\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一定量旋转\n",
    "- 一定量偏移\n",
    "- 用水平翻转\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='{0}_Xception_weights.h5'.format(prefix_cls), verbose=1,\n",
    "                               save_best_only=True, save_weights_only=True,mode='val_acc')\n",
    "\n",
    "#model.load_weights('{0}3_weights.h5'.format(prefix_cls))\n",
    "\n",
    "try:\n",
    "    # Fit the model\n",
    "    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                                  epochs=epochs, validation_data=(X_valid, y_valid),\n",
    "                                  verbose=2, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                                  callbacks=[EarlyStopping(patience=30), checkpointer])\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调整学习率lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = Xception(include_top=False, input_shape=(width, width, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((width, width, 3))\n",
    "\n",
    "x = inputs\n",
    "x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "x = cnn_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "adam = Adam(lr=0.0001) \n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Set a learning rate annealer\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "#                                             patience=3,\n",
    "#                                             verbose=1,\n",
    "#                                             factor=0.1,\n",
    "#                                             min_lr=0.00001)\n",
    "epochs = 32\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='{0}1_Xception_weights.h5'.format(prefix_cls), verbose=1,\n",
    "                               save_best_only=True, save_weights_only=True,mode='val_acc')\n",
    "\n",
    "model.load_weights('{0}_Xception_weights.h5'.format(prefix_cls))\n",
    "\n",
    "try:\n",
    "    # Fit the model\n",
    "    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                                  epochs=epochs, validation_data=(X_valid, y_valid),\n",
    "                                  verbose=2, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                                  callbacks=[EarlyStopping(patience=30), checkpointer])\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  对全量数据集进行数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center =False ,# set input mean to 0 over the dataset\n",
    "        samplewise_center = False ,# set each sample mean to 0\n",
    "        featurewise_std_normalization = False, # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization = False, # divide each input by its std\n",
    "        zca_whitening = False, # apply ZCA whitening\n",
    "        rotation_range = 10, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.3, # randomly zoom image\n",
    "        width_shift_range = 0.2, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range = 0.2, # randomly shift images vertivally (fraction of total heigth)\n",
    "        horizontal_flip = True, # randomly flip images\n",
    "        vertical_flip = False,\n",
    "        shear_range = 0.1,\n",
    "        fill_mode = 'constant',\n",
    "        cval = 0)\n",
    "\n",
    "\n",
    "\n",
    "datagen.fit(X,seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='{0}2_Xception_weights.h5'.format(prefix_cls), verbose=1,\n",
    "                               save_best_only=True, save_weights_only=True,mode='val_acc')\n",
    "\n",
    "model.load_weights('{0}1_Xception_weights.h5'.format(prefix_cls))\n",
    "\n",
    "try:\n",
    "    # Fit the model\n",
    "    history = model.fit_generator(datagen.flow(X, y, batch_size=batch_size),\n",
    "                                  epochs=epochs, validation_data=(X_valid, y_valid),\n",
    "                                  verbose=2, steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                                  callbacks=[EarlyStopping(patience=30), checkpointer])\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/collar_design_labels/faad3490a16c7f3d4f...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/collar_design_labels/0b2b4254f35ce3a41a...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/collar_design_labels/7f2be608e06f804dd5...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/collar_design_labels/4b09d4dca80caac42e...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/collar_design_labels/de91f00a05e84d7239...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class\n",
       "0  Images/collar_design_labels/faad3490a16c7f3d4f...  collar_design_labels\n",
       "1  Images/collar_design_labels/0b2b4254f35ce3a41a...  collar_design_labels\n",
       "2  Images/collar_design_labels/7f2be608e06f804dd5...  collar_design_labels\n",
       "3  Images/collar_design_labels/4b09d4dca80caac42e...  collar_design_labels\n",
       "4  Images/collar_design_labels/de91f00a05e84d7239...  collar_design_labels"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./z_rank/Tests/question.csv', header=None)\n",
    "df_test.columns = ['image_id', 'class', 'x']\n",
    "del df_test['x']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = df_test[(df_test['class'] == cur_class)].copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "\n",
    "print('{0}: {1}'.format(cur_class, len(df_load)))\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_load)\n",
    "X_test = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    X_test[i] = cv2.resize(cv2.imread('./z_rank/{0}'.format(df_load['image_id'][i])), (width, width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('{0}2_Xception_weights.h5'.format(prefix_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_np = model.predict(X_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for i, row in df_load.iterrows():\n",
    "    tmp_list = test_np[i]\n",
    "    tmp_result = ''\n",
    "    for tmp_ret in tmp_list:\n",
    "        tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        \n",
    "    result.append(tmp_result[:-1])\n",
    "\n",
    "df_load['result'] = result\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_load.to_csv('./result/{}_0419b_Xception_tta.csv'.format(prefix_cls), header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
