{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据\n",
    "-  label 文件一共有 79572 行\n",
    "- 各种维度混合在一起\n",
    "- 我们的目的是切分开各种维度, 进行训练和模拟\n",
    "- 那么首先取出个标签的图片进行聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/collar_design_labels/4d8a38b29930a403e5...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nnynn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/collar_design_labels/bd0981f231180d2b00...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/collar_design_labels/26937e1724feadfe39...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>ynnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/collar_design_labels/cf4140ec542887270f...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/collar_design_labels/50644b2b9de045f2d1...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "      <td>nynnn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class  \\\n",
       "0  Images/collar_design_labels/4d8a38b29930a403e5...  collar_design_labels   \n",
       "1  Images/collar_design_labels/bd0981f231180d2b00...  collar_design_labels   \n",
       "2  Images/collar_design_labels/26937e1724feadfe39...  collar_design_labels   \n",
       "3  Images/collar_design_labels/cf4140ec542887270f...  collar_design_labels   \n",
       "4  Images/collar_design_labels/50644b2b9de045f2d1...  collar_design_labels   \n",
       "\n",
       "   label  \n",
       "0  nnynn  \n",
       "1  nynnn  \n",
       "2  ynnnn  \n",
       "3  nynnn  \n",
       "4  nynnn  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./Annotations/label.csv', header=None)\n",
    "df_train.columns = ['image_id', 'class', 'label']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['collar_design_labels', 'neckline_design_labels', 'skirt_length_labels',\n",
    "          'sleeve_length_labels', 'neck_design_labels', 'coat_length_labels', 'lapel_design_labels',\n",
    "          'pant_length_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pant_length_labels: 7460\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/pant_length_labels/07264732b8dfa05ca485...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>ynnnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/pant_length_labels/ae01c534cddd89261c95...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>nnynnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/pant_length_labels/7d51f1a23c93213e4652...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>nnnnny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/pant_length_labels/5c9f7c834ae1c1daa3f5...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>nynnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/pant_length_labels/e1eb7a176c228107125d...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>nnnnyn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id               class  \\\n",
       "0  Images/pant_length_labels/07264732b8dfa05ca485...  pant_length_labels   \n",
       "1  Images/pant_length_labels/ae01c534cddd89261c95...  pant_length_labels   \n",
       "2  Images/pant_length_labels/7d51f1a23c93213e4652...  pant_length_labels   \n",
       "3  Images/pant_length_labels/5c9f7c834ae1c1daa3f5...  pant_length_labels   \n",
       "4  Images/pant_length_labels/e1eb7a176c228107125d...  pant_length_labels   \n",
       "\n",
       "    label  \n",
       "0  ynnnnn  \n",
       "1  nnynnn  \n",
       "2  nnnnny  \n",
       "3  nynnnn  \n",
       "4  nnnnyn  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_class = classes[7]\n",
    "df_load = df_train[(df_train['class'] == cur_class)].copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "\n",
    "print('{0}: {1}'.format(cur_class, len(df_load)))\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(df_load)\n",
    "n_class = len(df_load['label'][0])\n",
    "width = 299 # 定义图片大小\n",
    "\n",
    "X = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "y = np.zeros((n, n_class), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Images/pant_length_labels/07264732b8dfa05ca4857c71d2f9fb4b.jpg\n"
     ]
    }
   ],
   "source": [
    "print('./{0}'.format(df_load['image_id'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(df_load)\n",
    "n_class = len(df_load['label'][0])\n",
    "width = 299 # 定义图片大小\n",
    "\n",
    "X = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "y = np.zeros((n, n_class), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7460/7460 [00:42<00:00, 174.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n)):\n",
    "    tmp_label = df_load['label'][i]\n",
    "    if len(tmp_label) > n_class:\n",
    "        print(df_load['image_id'][i])\n",
    "    X[i] = cv2.resize(cv2.imread('./{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "    y[i][tmp_label.find('y')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7460, 299, 299, 3), (7460, 6))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.regularizers import *\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = InceptionResNetV2(include_top=False, input_shape=(width, width, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((width, width, 3))\n",
    "\n",
    "x = inputs\n",
    "x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "x = cnn_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pant'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "prefix_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练/测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6564, 299, 299, 3), (6564, 6))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.12, random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "adam = Adam(lr=0.0001) \n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Set a learning rate annealer\n",
    "# learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "#                                             patience=3,\n",
    "#                                             verbose=1,\n",
    "#                                             factor=0.1,\n",
    "#                                             min_lr=0.00001)\n",
    "epochs = 16\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center = False, # set input mean to 0 over the dataset\n",
    "        samplewise_center = False, # set each sample mean to 0\n",
    "        featurewise_std_normalization = False, # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization = False, # divide each input by its std\n",
    "        zca_whitening = False, # apply ZCA whitening\n",
    "        rotation_range = 10, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.05, # randomly zoom image\n",
    "        width_shift_range = 0.075, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range = 0.075, # randomly shift images vertivally (fraction of total heigth)\n",
    "        horizontal_flip = True, # randomly flip images\n",
    "        vertical_flip = False,\n",
    "        shear_range = 0.075,\n",
    "        fill_mode = 'constant',\n",
    "        cval = 0)\n",
    "\n",
    "datagen.fit(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 少量旋转\n",
    "- 少量偏移\n",
    "- 水平翻转\n",
    "- 垂直翻转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "Epoch 00001: val_loss improved from inf to 0.23490, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 231s - loss: 0.1970 - acc: 0.9268 - val_loss: 0.2349 - val_acc: 0.9129\n",
      "Epoch 2/16\n",
      "Epoch 00002: val_loss improved from 0.23490 to 0.18918, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 191s - loss: 0.1628 - acc: 0.9402 - val_loss: 0.1892 - val_acc: 0.9252\n",
      "Epoch 3/16\n",
      "Epoch 00003: val_loss improved from 0.18918 to 0.16655, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 191s - loss: 0.1512 - acc: 0.9459 - val_loss: 0.1666 - val_acc: 0.9364\n",
      "Epoch 4/16\n",
      "Epoch 00004: val_loss improved from 0.16655 to 0.12044, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 190s - loss: 0.1327 - acc: 0.9506 - val_loss: 0.1204 - val_acc: 0.9520\n",
      "Epoch 5/16\n",
      "Epoch 00005: val_loss improved from 0.12044 to 0.08504, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 190s - loss: 0.1079 - acc: 0.9610 - val_loss: 0.0850 - val_acc: 0.9665\n",
      "Epoch 6/16\n",
      "Epoch 00006: val_loss improved from 0.08504 to 0.07346, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 190s - loss: 0.0980 - acc: 0.9630 - val_loss: 0.0735 - val_acc: 0.9732\n",
      "Epoch 7/16\n",
      "Epoch 00007: val_loss improved from 0.07346 to 0.05530, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 190s - loss: 0.0960 - acc: 0.9635 - val_loss: 0.0553 - val_acc: 0.9777\n",
      "Epoch 8/16\n",
      "Epoch 00008: val_loss improved from 0.05530 to 0.03695, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 190s - loss: 0.0684 - acc: 0.9736 - val_loss: 0.0369 - val_acc: 0.9855\n",
      "Epoch 9/16\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 188s - loss: 0.0663 - acc: 0.9751 - val_loss: 0.0487 - val_acc: 0.9844\n",
      "Epoch 10/16\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./models/{0}.best0328_alldata.h5'.format(prefix_cls), verbose=1, \n",
    "                               save_best_only=True, mode='val_acc')\n",
    "\n",
    "try:\n",
    "    # Fit the model\n",
    "    history = model.fit_generator(datagen.flow(X, y, batch_size=batch_size),\n",
    "                                  epochs=epochs, validation_data=(X_valid, y_valid),\n",
    "                                  verbose=2, steps_per_epoch=X.shape[0] // batch_size,\n",
    "                                  callbacks=[EarlyStopping(patience=5), checkpointer])\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = InceptionResNetV2(include_top=False, input_shape=(width, width, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((width, width, 3))\n",
    "\n",
    "x = inputs\n",
    "x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "x = cnn_model(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./models/{}.best.h5'.format(prefix_cls)) #加载以前训练好的模型，继续测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "Epoch 00001: val_loss improved from inf to 0.23490, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 231s - loss: 0.1970 - acc: 0.9268 - val_loss: 0.2349 - val_acc: 0.9129\n",
      "Epoch 2/16\n",
      "Epoch 00002: val_loss improved from 0.23490 to 0.18918, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 191s - loss: 0.1628 - acc: 0.9402 - val_loss: 0.1892 - val_acc: 0.9252\n",
      "Epoch 3/16\n",
      "Epoch 00003: val_loss improved from 0.18918 to 0.16655, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 191s - loss: 0.1512 - acc: 0.9459 - val_loss: 0.1666 - val_acc: 0.9364\n",
      "Epoch 4/16\n",
      "Epoch 00004: val_loss improved from 0.16655 to 0.12044, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 190s - loss: 0.1327 - acc: 0.9506 - val_loss: 0.1204 - val_acc: 0.9520\n",
      "Epoch 5/16\n",
      "Epoch 00005: val_loss improved from 0.12044 to 0.08504, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 190s - loss: 0.1079 - acc: 0.9610 - val_loss: 0.0850 - val_acc: 0.9665\n",
      "Epoch 6/16\n",
      "Epoch 00006: val_loss improved from 0.08504 to 0.07346, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 190s - loss: 0.0980 - acc: 0.9630 - val_loss: 0.0735 - val_acc: 0.9732\n",
      "Epoch 7/16\n",
      "Epoch 00007: val_loss improved from 0.07346 to 0.05530, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 190s - loss: 0.0960 - acc: 0.9635 - val_loss: 0.0553 - val_acc: 0.9777\n",
      "Epoch 8/16\n",
      "Epoch 00008: val_loss improved from 0.05530 to 0.03695, saving model to ./models/pant.best0328_alldata.h5\n",
      " - 190s - loss: 0.0684 - acc: 0.9736 - val_loss: 0.0369 - val_acc: 0.9855\n",
      "Epoch 9/16\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 188s - loss: 0.0663 - acc: 0.9751 - val_loss: 0.0487 - val_acc: 0.9844\n",
      "Epoch 10/16\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "prefix_cls = cur_class.split('_')[0]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./models/{0}.best0328_alldata.h5'.format(prefix_cls), verbose=1, \n",
    "                               save_best_only=True, mode='val_acc')\n",
    "\n",
    "try:\n",
    "    # Fit the model\n",
    "    history = model.fit_generator(datagen.flow(X, y, batch_size=batch_size),\n",
    "                                  epochs=epochs, validation_data=(X_valid, y_valid),\n",
    "                                  verbose=2, steps_per_epoch=X.shape[0] // batch_size,\n",
    "                                  callbacks=[EarlyStopping(patience=5), checkpointer])\n",
    "except KeyboardInterrupt:\n",
    "    print('KeyboardInterrupt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/collar_design_labels/faad3490a16c7f3d4f...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/collar_design_labels/0b2b4254f35ce3a41a...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/collar_design_labels/7f2be608e06f804dd5...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/collar_design_labels/4b09d4dca80caac42e...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/collar_design_labels/de91f00a05e84d7239...</td>\n",
       "      <td>collar_design_labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id                 class\n",
       "0  Images/collar_design_labels/faad3490a16c7f3d4f...  collar_design_labels\n",
       "1  Images/collar_design_labels/0b2b4254f35ce3a41a...  collar_design_labels\n",
       "2  Images/collar_design_labels/7f2be608e06f804dd5...  collar_design_labels\n",
       "3  Images/collar_design_labels/4b09d4dca80caac42e...  collar_design_labels\n",
       "4  Images/collar_design_labels/de91f00a05e84d7239...  collar_design_labels"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./z_rank/Tests/question.csv', header=None)\n",
    "df_test.columns = ['image_id', 'class', 'x']\n",
    "del df_test['x']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pant_length_labels: 1434\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/pant_length_labels/e78538758763e84e9700...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/pant_length_labels/1e680886dd3d65882745...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/pant_length_labels/7e25106e7a0f5ac5d26a...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/pant_length_labels/53fa07f57908d258f4ba...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/pant_length_labels/737319237b262a9515a5...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id               class\n",
       "0  Images/pant_length_labels/e78538758763e84e9700...  pant_length_labels\n",
       "1  Images/pant_length_labels/1e680886dd3d65882745...  pant_length_labels\n",
       "2  Images/pant_length_labels/7e25106e7a0f5ac5d26a...  pant_length_labels\n",
       "3  Images/pant_length_labels/53fa07f57908d258f4ba...  pant_length_labels\n",
       "4  Images/pant_length_labels/737319237b262a9515a5...  pant_length_labels"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_load = df_test[(df_test['class'] == cur_class)].copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "\n",
    "print('{0}: {1}'.format(cur_class, len(df_load)))\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./z_rank/Images/pant_length_labels/e78538758763e84e97009dda11754b47.jpg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'./z_rank/{0}'.format(df_load['image_id'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1434/1434 [00:07<00:00, 196.61it/s]\n"
     ]
    }
   ],
   "source": [
    "n = len(df_load)\n",
    "X_test = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    X_test[i] = cv2.resize(cv2.imread('./z_rank/{0}'.format(df_load['image_id'][i])), (width, width))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./models/{}.best0328_alldata.h5'.format(prefix_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_np = model.predict(X_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1434, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Images/pant_length_labels/e78538758763e84e9700...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>0.0000;0.0000;0.0000;0.0179;0.7921;0.1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Images/pant_length_labels/1e680886dd3d65882745...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>0.0003;0.0013;0.9958;0.0002;0.0023;0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Images/pant_length_labels/7e25106e7a0f5ac5d26a...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>0.8980;0.1015;0.0000;0.0000;0.0003;0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Images/pant_length_labels/53fa07f57908d258f4ba...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>0.0000;0.0000;0.0000;0.7936;0.2048;0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Images/pant_length_labels/737319237b262a9515a5...</td>\n",
       "      <td>pant_length_labels</td>\n",
       "      <td>0.0000;0.0000;0.0000;0.0000;0.0088;0.9912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id               class  \\\n",
       "0  Images/pant_length_labels/e78538758763e84e9700...  pant_length_labels   \n",
       "1  Images/pant_length_labels/1e680886dd3d65882745...  pant_length_labels   \n",
       "2  Images/pant_length_labels/7e25106e7a0f5ac5d26a...  pant_length_labels   \n",
       "3  Images/pant_length_labels/53fa07f57908d258f4ba...  pant_length_labels   \n",
       "4  Images/pant_length_labels/737319237b262a9515a5...  pant_length_labels   \n",
       "\n",
       "                                      result  \n",
       "0  0.0000;0.0000;0.0000;0.0179;0.7921;0.1900  \n",
       "1  0.0003;0.0013;0.9958;0.0002;0.0023;0.0000  \n",
       "2  0.8980;0.1015;0.0000;0.0000;0.0003;0.0002  \n",
       "3  0.0000;0.0000;0.0000;0.7936;0.2048;0.0015  \n",
       "4  0.0000;0.0000;0.0000;0.0000;0.0088;0.9912  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for i, row in df_load.iterrows():\n",
    "    tmp_list = test_np[i]\n",
    "    tmp_result = ''\n",
    "    for tmp_ret in tmp_list:\n",
    "        tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        \n",
    "    result.append(tmp_result[:-1])\n",
    "\n",
    "df_load['result'] = result\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_load.to_csv('./result/{}_0418alldata.csv'.format('pant'), header=None, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
