{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 使用 [BayesianOptimization](https://github.com/fmfn/BayesianOptimization) 来寻找最佳权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../raw/train_data.csv')\n",
    "test_data = pd.read_csv('../raw/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8918"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去重\n",
    "train_data.drop_duplicates(train_data.columns.drop('ID'), keep='first', inplace=True)\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_train_data(train_data, test_data, poly=False, select=False):\n",
    "\n",
    "    y = train_data['发电量']\n",
    "    X = train_data.drop(['发电量','ID'], axis=1)\n",
    "    sub_data = test_data.drop(['ID'], axis=1)\n",
    "\n",
    "    if poly:\n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "        poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "        X = poly.fit_transform(X)\n",
    "        sub_data = poly.transform(sub_data)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if select:\n",
    "        from sklearn.feature_selection import SelectFromModel\n",
    "        sm = SelectFromModel(GradientBoostingRegressor(random_state=2))\n",
    "        X_train = sm.fit_transform(X_train, y_train)\n",
    "        X_test = sm.transform(X_test)\n",
    "        sub_data = sm.transform(sub_data)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test, sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7134, 191) (8409, 191)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, sub_data = generate_train_data(train_data, test_data, poly=True, select=False)\n",
    "print(X_train.shape, sub_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(round(max_depth))\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "\n",
    "    cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,\n",
    "             seed=random_state,\n",
    "             callbacks=[xgb.callback.early_stop(200)])\n",
    "    \n",
    "    rmse = cv_result['test-rmse-mean'].values[-1]\n",
    "    score = 1 / (1 + rmse)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[197]\ttrain-rmse:0.195878+0.0123012\ttest-rmse:0.208239+0.0411462\n",
      "\n",
      "    1 | 00m32s | \u001b[35m   0.82765\u001b[0m | \u001b[32m   5.7627\u001b[0m | \u001b[32m            0.8816\u001b[0m | \u001b[32m   8.9251\u001b[0m | \u001b[32m     8.9170\u001b[0m | \u001b[32m            4.7818\u001b[0m | \u001b[32m     0.9867\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[687]\ttrain-rmse:0.207072+0.0112054\ttest-rmse:0.217101+0.04095\n",
      "\n",
      "    2 | 00m50s |    0.82162 |    4.8094 |             0.1524 |    8.9623 |      8.3710 |            14.4551 |      0.5066 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[517]\ttrain-rmse:0.170178+0.00801758\ttest-rmse:0.198004+0.0431674\n",
      "\n",
      "    3 | 00m39s | \u001b[35m   0.83472\u001b[0m | \u001b[32m   0.4197\u001b[0m | \u001b[32m            0.9760\u001b[0m | \u001b[32m   6.6583\u001b[0m | \u001b[32m     7.2004\u001b[0m | \u001b[32m            5.4405\u001b[0m | \u001b[32m     0.9482\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[320]\ttrain-rmse:0.161837+0.00514652\ttest-rmse:0.192605+0.0449452\n",
      "\n",
      "    4 | 00m36s | \u001b[35m   0.83850\u001b[0m | \u001b[32m   2.5045\u001b[0m | \u001b[32m            0.1081\u001b[0m | \u001b[32m   3.5627\u001b[0m | \u001b[32m     8.6096\u001b[0m | \u001b[32m            5.3034\u001b[0m | \u001b[32m     0.6467\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[184]\ttrain-rmse:0.173951+0.0114196\ttest-rmse:0.192101+0.0452325\n",
      "\n",
      "    5 | 00m19s | \u001b[35m   0.83886\u001b[0m | \u001b[32m   3.6557\u001b[0m | \u001b[32m            0.6611\u001b[0m | \u001b[32m   3.0679\u001b[0m | \u001b[32m     6.6067\u001b[0m | \u001b[32m           11.0217\u001b[0m | \u001b[32m     0.9738\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "    6 | 02m15s | \u001b[35m   0.85795\u001b[0m | \u001b[32m   3.5250\u001b[0m | \u001b[32m            0.1000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m     5.0000\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     0.5000\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[705]\ttrain-rmse:0.129911+0.00912712\ttest-rmse:0.174405+0.0491092\n",
      "\n",
      "    7 | 00m53s |    0.85149 |    4.5394 |             0.1479 |    0.3080 |      5.0616 |             1.1630 |      0.9808 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "    8 | 02m17s |    0.85608 |    6.3486 |             1.0000 |    0.0000 |      7.5308 |             1.0000 |      0.5000 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "    9 | 01m48s |    0.85490 |    9.8434 |             0.8231 |    0.0005 |      5.5694 |             6.4337 |      0.5224 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3126]\ttrain-rmse:0.0422348+0.000278813\ttest-rmse:0.16515+0.0491297\n",
      "\n",
      "   10 | 02m46s | \u001b[35m   0.85826\u001b[0m | \u001b[32m   0.0510\u001b[0m | \u001b[32m            0.9448\u001b[0m | \u001b[32m   0.0337\u001b[0m | \u001b[32m     5.6027\u001b[0m | \u001b[32m            1.3594\u001b[0m | \u001b[32m     0.6475\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[199]\ttrain-rmse:0.128815+0.0100083\ttest-rmse:0.173515+0.0480872\n",
      "\n",
      "   11 | 00m33s |    0.85214 |    0.0331 |             0.9427 |    0.2055 |      5.1030 |            19.9231 |      0.6140 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1047]\ttrain-rmse:0.0724704+0.0021714\ttest-rmse:0.171042+0.0471892\n",
      "\n",
      "   12 | 01m06s |    0.85394 |    0.8745 |             0.9053 |    0.0558 |      5.0156 |             6.9965 |      0.5406 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3578]\ttrain-rmse:0.170735+0.0112051\ttest-rmse:0.187734+0.0459285\n",
      "\n",
      "   13 | 03m04s |    0.84194 |    9.7164 |             0.8969 |    0.4162 |      6.5264 |            19.4779 |      0.5282 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[419]\ttrain-rmse:0.200553+0.012885\ttest-rmse:0.209911+0.0411614\n",
      "\n",
      "   14 | 00m43s |    0.82651 |    9.9491 |             0.8798 |    4.9627 |      5.3788 |             1.5445 |      0.5638 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[624]\ttrain-rmse:0.105632+0.00435478\ttest-rmse:0.172776+0.0485723\n",
      "\n",
      "   15 | 01m12s |    0.85268 |    2.3135 |             0.9080 |    0.1369 |      8.7489 |            19.6588 |      0.5930 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2539]\ttrain-rmse:0.156962+0.0114113\ttest-rmse:0.180044+0.0489546\n",
      "\n",
      "   16 | 02m45s |    0.84743 |    9.7231 |             0.9347 |    0.1838 |      8.9306 |             8.7318 |      0.6074 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1369]\ttrain-rmse:0.0148022+0.000132655\ttest-rmse:0.164526+0.0493331\n",
      "\n",
      "   17 | 01m53s | \u001b[35m   0.85872\u001b[0m | \u001b[32m   0.3320\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m     8.1248\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     0.5000\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "   18 | 02m39s |    0.85675 |    3.5643 |             0.9506 |    0.0023 |      5.7774 |             1.6198 |      0.5875 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1513]\ttrain-rmse:0.101436+0.0047481\ttest-rmse:0.169259+0.0495821\n",
      "\n",
      "   19 | 01m17s |    0.85524 |    5.2489 |             0.4847 |    0.0103 |      5.1406 |            15.3746 |      0.5715 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[88]\ttrain-rmse:0.127899+0.0125588\ttest-rmse:0.172174+0.0480565\n",
      "\n",
      "   20 | 00m37s |    0.85312 |    0.0642 |             0.9378 |    0.0827 |      8.2028 |            16.0992 |      0.5952 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2121]\ttrain-rmse:0.0646002+0.000832822\ttest-rmse:0.171847+0.0484836\n",
      "\n",
      "   21 | 01m45s |    0.85335 |    0.2902 |             0.3515 |    0.0953 |      5.2408 |             1.1139 |      0.5488 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[687]\ttrain-rmse:0.200055+0.0109885\ttest-rmse:0.210511+0.0413763\n",
      "\n",
      "   22 | 01m21s |    0.82610 |    0.0192 |             0.8362 |    9.9901 |      8.8984 |            19.6094 |      0.5883 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1424]\ttrain-rmse:0.16861+0.00461573\ttest-rmse:0.207266+0.0414517\n",
      "\n",
      "   23 | 02m15s |    0.82832 |    0.0844 |             0.1037 |    9.9200 |      8.8899 |             1.3355 |      0.6070 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "   24 | 02m06s |    0.85228 |    9.5270 |             0.2431 |    0.0244 |      5.7202 |             2.1252 |      0.5160 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[687]\ttrain-rmse:0.210007+0.0116002\ttest-rmse:0.218094+0.0400369\n",
      "\n",
      "   25 | 00m52s |    0.82095 |    9.8169 |             0.7213 |    9.9785 |      5.4211 |            19.8309 |      0.5940 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "   26 | 02m42s |    0.84623 |    9.7544 |             0.2082 |    0.3114 |      5.0139 |            13.8164 |      0.7186 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[446]\ttrain-rmse:0.21087+0.0117543\ttest-rmse:0.219739+0.0394463\n",
      "\n",
      "   27 | 00m55s |    0.81985 |    9.9749 |             0.8118 |    8.9516 |      8.9543 |            19.7698 |      0.5328 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[815]\ttrain-rmse:0.140624+0.00580976\ttest-rmse:0.179822+0.0480236\n",
      "\n",
      "   28 | 00m59s |    0.84759 |    4.8207 |             0.9968 |    0.2786 |      5.1710 |            19.7806 |      0.5094 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3180]\ttrain-rmse:0.0872186+0.00316177\ttest-rmse:0.169184+0.0500056\n",
      "\n",
      "   29 | 02m15s |    0.85530 |    5.2867 |             0.9557 |    0.0045 |      7.4639 |            10.5230 |      0.5148 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3154]\ttrain-rmse:0.119775+0.006007\ttest-rmse:0.172512+0.0482084\n",
      "\n",
      "   30 | 03m28s |    0.85287 |    6.3793 |             0.1365 |    0.0537 |      8.8765 |            19.8939 |      0.7570 | \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    num_rounds = 4000\n",
    "    random_state = 42\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    params = {\n",
    "        'eta': 0.1,\n",
    "        'silent': 1,\n",
    "        'objective': 'reg:linear',\n",
    "        'booster': 'gbtree',\n",
    "        'eval_metric': 'rmse',\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state,\n",
    "        'tree_method': 'exact'\n",
    "    }\n",
    "    \n",
    "    xgbBO = BayesianOptimization(xgb_evaluate, {'min_child_weight': (1, 20),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'max_depth': (5, 8.99),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'gamma': (0, 10),\n",
    "                                                'alpha': (0, 10),\n",
    "                                                })\n",
    "\n",
    "    xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
    "30   | 02m31s |    0.86199 |    3.1606 |             0.4358 |    0.0084 |      5.3738 |            19.6339 |      0.9666 |\n",
    "12   | 00m50s |    0.86102 |    0.2264 |             0.1635 |    0.0172 |      5.6864 |            18.6665 |      0.5565 |\n",
    "17   | 01m53s |    0.85872 |    0.3320 |             1.0000 |    0.0000 |      8.1248 |             1.0000 |      0.5000 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调参 lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lgb_eval(num_leaves,\n",
    "             min_data,\n",
    "             sub_feature\n",
    "            ):\n",
    "\n",
    "    params['num_leaves'] = int(round(num_leaves))\n",
    "    params['min_data'] = int(min_data)\n",
    "    params['sub_feature'] = max(min(sub_feature, 1), 0)\n",
    "    \n",
    "    gbm = lgb.train(params, lgb_train, 4000)\n",
    "    \n",
    "    pred = gbm.predict(X_test)\n",
    "    rmsetmp = sp.sqrt(sp.mean((y_test - pred) ** 2))\n",
    "    score = 1 / (1 + rmsetmp)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (20, 200),\n",
    "                                        'min_data': (10, 80),\n",
    "                                        'sub_feature': (0.3, 1)\n",
    "                                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    num_rounds = 4000\n",
    "    random_state = 42\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    params = {\n",
    "        'eta': 0.1,\n",
    "        'learning_rate': 0.002,\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'metric': 'rmse',\n",
    "        'min_hessian': 1,\n",
    "        'verbose': -1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   min_data |   num_leaves |   sub_feature | \n",
      "    1 | 02m03s | \u001b[35m   0.89883\u001b[0m | \u001b[32m   62.4191\u001b[0m | \u001b[32m    158.5493\u001b[0m | \u001b[32m       0.6738\u001b[0m | \n",
      "    2 | 02m08s |    0.89798 |    67.4945 |     194.8964 |        0.8054 | \n",
      "    3 | 03m01s | \u001b[35m   0.89926\u001b[0m | \u001b[32m   42.4281\u001b[0m | \u001b[32m    135.4756\u001b[0m | \u001b[32m       0.6116\u001b[0m | \n",
      "    4 | 02m09s | \u001b[35m   0.89967\u001b[0m | \u001b[32m   53.3468\u001b[0m | \u001b[32m    162.9040\u001b[0m | \u001b[32m       0.3697\u001b[0m | \n",
      "    5 | 03m16s |    0.89698 |    19.8272 |     118.3053 |        0.7556 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   min_data |   num_leaves |   sub_feature | \n",
      "    6 | 00m41s |    0.89400 |    79.7722 |      20.2748 |        0.4218 | \n",
      "    7 | 06m06s |    0.89175 |    10.2518 |     198.8416 |        0.9781 | \n",
      "    8 | 00m42s |    0.89409 |    10.3181 |      20.2125 |        0.3546 | \n",
      "    9 | 01m46s |    0.89935 |    49.4924 |      70.9616 |        0.3010 | \n",
      "   10 | 02m05s |    0.89953 |    54.2692 |     115.5959 |        0.3058 | \n",
      "   11 | 02m22s |    0.89935 |    47.9138 |     145.8885 |        0.3042 | \n",
      "   12 | 00m41s |    0.89465 |    45.2157 |      20.1223 |        0.3039 | \n",
      "   13 | 02m03s |    0.89853 |    78.7942 |      79.3357 |        0.9959 | \n",
      "   14 | 03m34s |    0.89704 |    45.4176 |     187.7768 |        0.9774 | \n",
      "   15 | 01m38s |    0.89884 |    79.7781 |     180.7110 |        0.3192 | \n",
      "   16 | 01m29s |    0.89877 |    70.9900 |      57.6638 |        0.3038 | \n",
      "   17 | 02m04s |    0.89926 |    59.8869 |      86.0774 |        0.3081 | \n",
      "   18 | 01m32s |    0.89566 |    10.3802 |      58.4294 |        0.3040 | \n",
      "   19 | 02m23s |    0.89927 |    40.2218 |     103.2296 |        0.3258 | \n",
      "   20 | 01m30s |    0.89886 |    79.6856 |     199.6007 |        0.3339 | \n",
      "   21 | 03m25s |    0.89816 |    29.0467 |     160.6355 |        0.3113 | \n",
      "   22 | 02m42s |    0.89921 |    42.1574 |     121.4290 |        0.3217 | \n",
      "   23 | 01m58s |    0.89897 |    51.4008 |      58.4690 |        0.9920 | \n",
      "   24 | 03m22s |    0.89718 |    46.3500 |     160.3007 |        0.9965 | \n",
      "   25 | 01m38s |    0.89882 |    79.8546 |     124.4909 |        0.3378 | \n",
      "   26 | 03m31s |    0.89553 |    10.1177 |     146.9458 |        0.3125 | \n",
      "   27 | 01m14s |    0.89881 |    33.1445 |      45.4492 |        0.3021 | \n",
      "   28 | 02m21s |    0.89946 |    49.6631 |     199.9075 |        0.3214 | \n",
      "   29 | 01m36s |    0.89882 |    79.7591 |     101.1459 |        0.3408 | \n",
      "   30 | 02m14s |    0.89927 |    60.4189 |     177.6279 |        0.3125 | \n"
     ]
    }
   ],
   "source": [
    "lgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbrt_evaluate(n_estimators,\n",
    "                 max_depth):\n",
    "    \n",
    "    est = GradientBoostingRegressor(n_estimators=int(n_estimators),\n",
    "                                max_depth=int(max_depth),\n",
    "                                random_state=42,\n",
    "                                loss='ls',\n",
    "                                learning_rate = 0.1\n",
    "        ).fit(X_train, y_train)\n",
    "    \n",
    "    prediction3 = est.predict(X_test)\n",
    "    rmse = sp.sqrt(sp.mean((y_test - prediction3) ** 2))\n",
    "    score = 1 / (1 + rmse)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   n_estimators | \n",
      "    1 | 04m17s | \u001b[35m   0.88928\u001b[0m | \u001b[32m     5.2015\u001b[0m | \u001b[32m     5611.3857\u001b[0m | \n",
      "    2 | 08m30s |    0.88767 |      9.8151 |      7358.5853 | \n",
      "    3 | 05m36s |    0.88928 |      5.3633 |      7559.6278 | \n",
      "    4 | 07m02s | \u001b[35m   0.89188\u001b[0m | \u001b[32m     6.3352\u001b[0m | \u001b[32m     8551.1300\u001b[0m | \n",
      "    5 | 05m42s |    0.88928 |      5.2315 |      7945.1096 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   max_depth |   n_estimators | \n",
      "    6 | 00m11s |    0.88967 |      6.5478 |       100.0683 | \n",
      "    7 | 02m03s |    0.88927 |      5.0103 |      2344.9942 | \n",
      "    8 | 06m42s |    0.88928 |      5.1478 |      9999.7556 | \n",
      "    9 | 03m30s |    0.88928 |      5.0034 |      3893.6679 | \n",
      "   10 | 01m09s |    0.88914 |      5.0059 |      1033.2178 | \n",
      "   11 | 07m23s |    0.88928 |      5.0197 |      9374.3662 | \n",
      "   12 | 04m28s |    0.88928 |      5.0001 |      4768.8030 | \n",
      "   13 | 03m02s |    0.88928 |      5.0011 |      3077.9292 | \n",
      "   14 | 00m31s |    0.88835 |      5.0099 |       488.0452 | \n",
      "   15 | 06m34s |    0.88928 |      5.0090 |      8845.5375 | \n",
      "   16 | 01m36s |    0.88921 |      5.0217 |      1695.9306 | \n",
      "   17 | 05m19s |    0.88928 |      5.0073 |      6310.1348 | \n",
      "   18 | 06m30s |    0.88928 |      5.0197 |      8392.5217 | \n",
      "   19 | 05m34s |    0.88767 |      9.9833 |      4343.3856 | \n",
      "   20 | 10m37s |    0.88767 |      9.9952 |      9732.9851 | \n",
      "   21 | 06m34s |    0.88767 |      9.9628 |      5198.5803 | \n",
      "   22 | 04m30s |    0.88767 |      9.9884 |      3484.0699 | \n",
      "   23 | 07m06s |    0.88767 |      9.9694 |      5981.1627 | \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-26bf43d85792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                 })\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgbrtBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;31m# Append most recently generated values to X and Y arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mobserve_point\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# measure the target function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-156-f442097e7f72>\u001b[0m in \u001b[0;36mgbrt_evaluate\u001b[0;34m(n_estimators, max_depth)\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ls'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                 \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         ).fit(X_train, y_train)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprediction3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 788\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    random_state = 42\n",
    "    num_iter = 25\n",
    "    init_points = 5\n",
    "    \n",
    "    gbrtBO = BayesianOptimization(gbrt_evaluate, {'n_estimators': (100, 10000),\n",
    "                                                  'max_depth': (5, 10)\n",
    "                                                })\n",
    "\n",
    "    gbrtBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
